{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      One of the other reviewers has mentioned that ...  positive\n",
       "1      A wonderful little production. <br /><br />The...  positive\n",
       "2      I thought this was a wonderful way to spend ti...  positive\n",
       "3      Basically there's a family where a little boy ...  negative\n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  I thought this movie did a down right good job...  positive\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  I am a Catholic taught in parochial elementary...  negative\n",
       "49998  I'm going to have to disagree with the previou...  negative\n",
       "49999  No one expects the Star Trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('senti9.csv')\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of                                                   review sentiment\n",
       "0      One of the other reviewers has mentioned that ...  positive\n",
       "1      A wonderful little production. <br /><br />The...  positive\n",
       "2      I thought this was a wonderful way to spend ti...  positive\n",
       "3      Basically there's a family where a little boy ...  negative\n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  I thought this movie did a down right good job...  positive\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  I am a Catholic taught in parochial elementary...  negative\n",
       "49998  I'm going to have to disagree with the previou...  negative\n",
       "49999  No one expects the Star Trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['review', 'sentiment'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49582, 2)\n"
     ]
    }
   ],
   "source": [
    "df.drop_duplicates(inplace=True)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "review       0\n",
      "sentiment    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [One, reviewers, mentioned, watching, 1, Oz, e...\n",
       "1    [wonderful, little, production, br, br, filmin...\n",
       "2    [thought, wonderful, way, spend, time, hot, su...\n",
       "3    [Basically, theres, family, little, boy, Jake,...\n",
       "4    [Petter, Matteis, Love, Time, Money, visually,...\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process(text):\n",
    "    nopunc = [char for char in text if char not in string.punctuation]\n",
    "    nopunc = ''.join(nopunc)\n",
    "\n",
    "    clean = [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]\n",
    "    return clean\n",
    "# to show how the tokenization will take place\n",
    "df['review'].head().apply(process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert collection of words in matrix \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "stopset = set(stopwords.words('english'))\n",
    "vector = TfidfVectorizer(use_idf=True, lowercase=True , strip_accents='ascii' , stop_words = stopset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 81735)\t0.046909423357689384\n",
      "  (0, 22625)\t0.0741715723188564\n",
      "  (0, 91779)\t0.057469196048511154\n",
      "  (0, 90143)\t0.06203235610057424\n",
      "  (0, 96993)\t0.05235283229958593\n",
      "  (0, 94123)\t0.07156848297095121\n",
      "  (0, 18632)\t0.07304795993751523\n",
      "  (0, 8982)\t0.045144024513614954\n",
      "  (0, 56534)\t0.036998231077040734\n",
      "  (0, 31346)\t0.04817988305079993\n",
      "  (0, 82436)\t0.06478502242034845\n",
      "  (0, 86423)\t0.05508209420752167\n",
      "  (0, 50949)\t0.04873534078272289\n",
      "  (0, 10378)\t0.10062362659413682\n",
      "  (0, 93290)\t0.049747787045981165\n",
      "  (0, 17537)\t0.0517773419118707\n",
      "  (0, 58076)\t0.04984747481202113\n",
      "  (0, 55518)\t0.08438001666326782\n",
      "  (0, 98647)\t0.02515185509498216\n",
      "  (0, 37010)\t0.05291248867548508\n",
      "  (0, 64469)\t0.049827467485849826\n",
      "  (0, 49632)\t0.04801383491398172\n",
      "  (0, 45652)\t0.1701783995778295\n",
      "  (0, 62186)\t0.10390728059051213\n",
      "  (0, 83694)\t0.07010042149916931\n",
      "  :\t:\n",
      "  (49581, 43277)\t0.08263934792246524\n",
      "  (49581, 32082)\t0.09652644945909525\n",
      "  (49581, 85442)\t0.0981781270951443\n",
      "  (49581, 100256)\t0.08959751784536739\n",
      "  (49581, 60248)\t0.19898777734956064\n",
      "  (49581, 38090)\t0.051449491109019106\n",
      "  (49581, 9768)\t0.06906416175633819\n",
      "  (49581, 4930)\t0.07703381481988167\n",
      "  (49581, 98226)\t0.06603207594185925\n",
      "  (49581, 60212)\t0.2731902659271539\n",
      "  (49581, 30774)\t0.10965324393880746\n",
      "  (49581, 16057)\t0.06764810316338482\n",
      "  (49581, 68882)\t0.06836111079002913\n",
      "  (49581, 98351)\t0.06387122901417189\n",
      "  (49581, 100258)\t0.18084238245799064\n",
      "  (49581, 79715)\t0.11110955958165504\n",
      "  (49581, 98647)\t0.05764868839672956\n",
      "  (49581, 78511)\t0.07189955231136368\n",
      "  (49581, 100278)\t0.05568166745265551\n",
      "  (49581, 32200)\t0.17174969581244234\n",
      "  (49581, 41959)\t0.09424362000914255\n",
      "  (49581, 78732)\t0.07445097588516338\n",
      "  (49581, 12068)\t0.08044276911757865\n",
      "  (49581, 98242)\t0.07547317578119292\n",
      "  (49581, 64112)\t0.04091782331664606\n"
     ]
    }
   ],
   "source": [
    "message = vector.fit_transform(df['review'])\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49582, 101865)\n"
     ]
    }
   ],
   "source": [
    "#spliting the data into 80% training and 20% testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(message, df['sentiment'], test_size=0.20, random_state=4)\n",
    "# here we can see the shape of the data\n",
    "print(message.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 67520)\t0.1802876392768567\n",
      "  (0, 10530)\t0.36457055918762404\n",
      "  (0, 46788)\t0.14259744842954716\n",
      "  (0, 6588)\t0.1433930916120579\n",
      "  (0, 25337)\t0.12919738158533484\n",
      "  (0, 29496)\t0.13534770680400787\n",
      "  (0, 96136)\t0.24952539190708595\n",
      "  (0, 31270)\t0.3089669200334479\n",
      "  (0, 85722)\t0.1343132659044895\n",
      "  (0, 38330)\t0.10588933340636057\n",
      "  (0, 9379)\t0.13448180076430033\n",
      "  (0, 20055)\t0.11287807332991301\n",
      "  (0, 73426)\t0.09099472584224556\n",
      "  (0, 72401)\t0.13011604104613972\n",
      "  (0, 62903)\t0.11573768239097719\n",
      "  (0, 16824)\t0.09398587785653613\n",
      "  (0, 85913)\t0.09603247032267977\n",
      "  (0, 69701)\t0.12142453028707469\n",
      "  (0, 44694)\t0.09822669271487397\n",
      "  (0, 30842)\t0.06733033113233823\n",
      "  (0, 84060)\t0.11177329209980356\n",
      "  (0, 70531)\t0.11131883513140763\n",
      "  (0, 78720)\t0.13607008167497528\n",
      "  (0, 45036)\t0.09062261663593474\n",
      "  (0, 23123)\t0.07996448061123537\n",
      "  :\t:\n",
      "  (39664, 7604)\t0.05101239175007436\n",
      "  (39664, 9312)\t0.07165270579483903\n",
      "  (39664, 61687)\t0.07846928970584305\n",
      "  (39664, 93384)\t0.07202144721211386\n",
      "  (39664, 35647)\t0.07201655276387908\n",
      "  (39664, 79752)\t0.053006021676464996\n",
      "  (39664, 54037)\t0.11783876256956365\n",
      "  (39664, 33359)\t0.062461009338023954\n",
      "  (39664, 37022)\t0.0681422516169768\n",
      "  (39664, 4930)\t0.061387474547436836\n",
      "  (39664, 98226)\t0.0526202991591833\n",
      "  (39664, 55045)\t0.10034712972911143\n",
      "  (39664, 60212)\t0.06220073811712386\n",
      "  (39664, 30774)\t0.04369078525499774\n",
      "  (39664, 16057)\t0.053908095046759696\n",
      "  (39664, 68882)\t0.054476283674508394\n",
      "  (39664, 98351)\t0.05089834191112968\n",
      "  (39664, 30831)\t0.06315637091793924\n",
      "  (39664, 80022)\t0.07377191351158645\n",
      "  (39664, 90935)\t0.08584076386525598\n",
      "  (39664, 53148)\t0.05561226490939184\n",
      "  (39664, 37010)\t0.14496635455946577\n",
      "  (39664, 64469)\t0.09100946990233698\n",
      "  (39664, 14109)\t0.0823183852686743\n",
      "  (39664, 37791)\t0.058661018898445674\n"
     ]
    }
   ],
   "source": [
    "print(xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34694    negative\n",
      "36086    positive\n",
      "47515    positive\n",
      "14690    positive\n",
      "25605    negative\n",
      "           ...   \n",
      "23442    negative\n",
      "11885    negative\n",
      "27181    positive\n",
      "8377     positive\n",
      "17583    negative\n",
      "Name: sentiment, Length: 39665, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 93450)\t0.2245688263676923\n",
      "  (0, 46795)\t0.2245688263676923\n",
      "  (0, 41511)\t0.2245688263676923\n",
      "  (0, 34692)\t0.2245688263676923\n",
      "  (0, 33600)\t0.19656816745179317\n",
      "  (0, 69833)\t0.16734299994306095\n",
      "  (0, 11978)\t0.190135973427472\n",
      "  (0, 70507)\t0.13390642485230467\n",
      "  (0, 21841)\t0.10337602635381739\n",
      "  (0, 27708)\t0.1679459762388802\n",
      "  (0, 1095)\t0.14362788566343015\n",
      "  (0, 87875)\t0.1302806728809082\n",
      "  (0, 55879)\t0.13519486311092876\n",
      "  (0, 68389)\t0.15394564678093062\n",
      "  (0, 35490)\t0.13448191124135608\n",
      "  (0, 56157)\t0.12633119859680964\n",
      "  (0, 89727)\t0.11821966715656902\n",
      "  (0, 18842)\t0.14088493817630593\n",
      "  (0, 62557)\t0.10305324545089924\n",
      "  (0, 47983)\t0.1050993987420941\n",
      "  (0, 83546)\t0.09661209633626074\n",
      "  (0, 57627)\t0.12174626402020008\n",
      "  (0, 77198)\t0.12125509803382878\n",
      "  (0, 69447)\t0.10853812260127291\n",
      "  (0, 85565)\t0.11962438642224456\n",
      "  :\t:\n",
      "  (9916, 38090)\t0.011560200904417341\n",
      "  (9916, 100193)\t0.09366912493153756\n",
      "  (9916, 57)\t0.0176394302812594\n",
      "  (9916, 52755)\t0.020798562772008145\n",
      "  (9916, 33219)\t0.018664311347157042\n",
      "  (9916, 37942)\t0.01762804425476023\n",
      "  (9916, 12024)\t0.02366886932185166\n",
      "  (9916, 35309)\t0.02230847337243194\n",
      "  (9916, 100891)\t0.017346996128353543\n",
      "  (9916, 95830)\t0.03788910609278456\n",
      "  (9916, 69080)\t0.01926626723505576\n",
      "  (9916, 30774)\t0.024638018810869917\n",
      "  (9916, 3283)\t0.02817447698141885\n",
      "  (9916, 79715)\t0.01248261939504487\n",
      "  (9916, 90935)\t0.012101787267657847\n",
      "  (9916, 63968)\t0.017663148887633456\n",
      "  (9916, 53148)\t0.031360755384819826\n",
      "  (9916, 83694)\t0.036101424277304076\n",
      "  (9916, 6845)\t0.030041825761800634\n",
      "  (9916, 37914)\t0.02044817332084144\n",
      "  (9916, 31782)\t0.022844337214302762\n",
      "  (9916, 14109)\t0.02321040824618774\n",
      "  (9916, 33530)\t0.027956025008763447\n",
      "  (9916, 12068)\t0.05422412655178918\n",
      "  (9916, 64112)\t0.027581512348270474\n"
     ]
    }
   ],
   "source": [
    "print(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34403    positive\n",
      "3542     positive\n",
      "43726    negative\n",
      "2060     positive\n",
      "40294    positive\n",
      "           ...   \n",
      "11721    negative\n",
      "28392    positive\n",
      "32777    positive\n",
      "23939    negative\n",
      "40642    negative\n",
      "Name: sentiment, Length: 9917, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating and training the Naive Bayes Classifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier1 = MultinomialNB().fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['positive', 'positive', 'positive', 'negative', 'negative',\n",
       "       'positive', 'positive', 'positive', 'negative', 'negative',\n",
       "       'negative', 'negative', 'negative', 'negative', 'positive',\n",
       "       'negative', 'negative', 'positive', 'positive', 'negative',\n",
       "       'negative', 'positive', 'positive', 'positive', 'positive',\n",
       "       'negative', 'negative', 'negative', 'negative', 'positive',\n",
       "       'negative', 'negative', 'negative', 'positive', 'positive',\n",
       "       'positive', 'negative', 'positive', 'negative', 'positive',\n",
       "       'negative', 'positive', 'positive', 'positive', 'negative',\n",
       "       'positive', 'positive', 'positive', 'negative', 'negative',\n",
       "       'positive', 'positive', 'positive', 'positive', 'negative',\n",
       "       'positive', 'negative', 'positive', 'positive', 'positive',\n",
       "       'negative', 'negative', 'negative', 'positive', 'positive',\n",
       "       'negative', 'negative', 'positive', 'positive', 'negative',\n",
       "       'positive', 'positive', 'negative', 'positive', 'positive',\n",
       "       'positive', 'positive', 'negative', 'positive', 'positive',\n",
       "       'negative', 'negative', 'negative', 'positive', 'negative',\n",
       "       'positive', 'negative', 'negative', 'positive', 'negative',\n",
       "       'positive', 'positive', 'negative', 'negative', 'negative',\n",
       "       'positive', 'positive', 'negative', 'positive'], dtype='<U8')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc = classifier1.predict(xtrain)\n",
    "abc[1:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['positive', 'positive', 'positive', 'negative', 'negative',\n",
       "       'positive', 'positive', 'positive', 'negative', 'negative',\n",
       "       'negative', 'negative', 'negative', 'positive', 'positive',\n",
       "       'negative', 'negative', 'positive', 'positive', 'negative',\n",
       "       'negative', 'positive', 'positive', 'positive', 'positive',\n",
       "       'negative', 'negative', 'negative', 'negative', 'positive',\n",
       "       'negative', 'negative', 'negative', 'positive', 'positive',\n",
       "       'positive', 'negative', 'positive', 'positive', 'negative',\n",
       "       'negative', 'positive', 'positive', 'positive', 'negative',\n",
       "       'positive', 'positive', 'positive', 'negative', 'negative',\n",
       "       'positive', 'positive', 'positive', 'positive', 'negative',\n",
       "       'positive', 'negative', 'positive', 'positive', 'positive',\n",
       "       'negative', 'negative', 'negative', 'positive', 'positive',\n",
       "       'negative', 'negative', 'positive', 'positive', 'negative',\n",
       "       'negative', 'positive', 'negative', 'positive', 'positive',\n",
       "       'positive', 'positive', 'negative', 'positive', 'positive',\n",
       "       'negative', 'negative', 'negative', 'positive', 'negative',\n",
       "       'positive', 'negative', 'negative', 'positive', 'negative',\n",
       "       'positive', 'positive', 'negative', 'negative', 'negative',\n",
       "       'positive', 'positive', 'negative', 'positive'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xyz = ytrain.values\n",
    "xyz[1:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.92      0.91     19768\n",
      "    positive       0.92      0.90      0.91     19897\n",
      "\n",
      "    accuracy                           0.91     39665\n",
      "   macro avg       0.91      0.91      0.91     39665\n",
      "weighted avg       0.91      0.91      0.91     39665\n",
      "\n",
      "\n",
      "Confusion Matrix: \n",
      " [[18167  1601]\n",
      " [ 2023 17874]]\n",
      "Accuracy: \n",
      " 0.9086348165889323\n"
     ]
    }
   ],
   "source": [
    "#Model evaluation on the training data set\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "pred = classifier1.predict(xtrain)\n",
    "print(classification_report(ytrain, pred))\n",
    "print()\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(ytrain, pred))\n",
    "print(\"Accuracy: \\n\", accuracy_score(ytrain, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.88      0.87      4930\n",
      "    positive       0.87      0.85      0.86      4987\n",
      "\n",
      "    accuracy                           0.86      9917\n",
      "   macro avg       0.86      0.86      0.86      9917\n",
      "weighted avg       0.86      0.86      0.86      9917\n",
      "\n",
      "\n",
      "Confusion Matrix: \n",
      " [[4322  608]\n",
      " [ 734 4253]]\n",
      "Accuracy: \n",
      " 0.8646768175859635\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on the testing data set\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "pred = classifier1.predict(xtest)\n",
    "print(classification_report(ytest, pred))\n",
    "print()\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(ytest, pred))\n",
    "print(\"Accuracy: \\n\", accuracy_score(ytest, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['positive' 'positive' 'negative' ... 'positive' 'negative' 'negative']\n",
      "['positive' 'positive' 'negative' ... 'positive' 'negative' 'negative']\n"
     ]
    }
   ],
   "source": [
    "#printing the prediction result\n",
    "print(classifier1.predict(xtest))\n",
    "#printing  the actual values\n",
    "print(ytest.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trump teases possible 2024 run at his 1st big ...</td>\n",
       "      <td>2 days ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Charges expected Thursday for Trump''s company...</td>\n",
       "      <td>14 mins ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Donald Trump heads to US-Mexico border for fre...</td>\n",
       "      <td>5 hours ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>With 15 millionaires Biden Cabinetâ€™s net worth...</td>\n",
       "      <td>3 hours ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trump had to cancel a July 4 weekend rally at ...</td>\n",
       "      <td>4 hours ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>Trump Organization and CFO Weisselberg Will Be...</td>\n",
       "      <td>15 mins ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>Trump blasts former ally McConnell after book ...</td>\n",
       "      <td>1 day ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>Trump's followers do take him literally</td>\n",
       "      <td>2 hours ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>Xbox Remote Play Gameplay Usage Review on Seri...</td>\n",
       "      <td>4 hours ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>U.S. Should Distance From Trump-Era Trade Key ...</td>\n",
       "      <td>23 hours ago</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>779 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text           time\n",
       "0    Trump teases possible 2024 run at his 1st big ...     2 days ago\n",
       "1    Charges expected Thursday for Trump''s company...    14 mins ago\n",
       "2    Donald Trump heads to US-Mexico border for fre...    5 hours ago\n",
       "3    With 15 millionaires Biden Cabinetâ€™s net worth...    3 hours ago\n",
       "4    Trump had to cancel a July 4 weekend rally at ...    4 hours ago\n",
       "..                                                 ...            ...\n",
       "774  Trump Organization and CFO Weisselberg Will Be...    15 mins ago\n",
       "775  Trump blasts former ally McConnell after book ...      1 day ago\n",
       "776            Trump's followers do take him literally    2 hours ago\n",
       "777  Xbox Remote Play Gameplay Usage Review on Seri...    4 hours ago\n",
       "778  U.S. Should Distance From Trump-Era Trade Key ...   23 hours ago\n",
       "\n",
       "[779 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('news3.csv')\n",
    "df1 = pd.DataFrame(data)\n",
    "df1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "message1 = df1['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "message2 = np.array([\"taylor is a good slut\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['negative' 'positive' 'positive' 'negative' 'negative' 'negative'\n",
      " 'positive' 'negative' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'negative' 'negative' 'negative' 'positive' 'positive'\n",
      " 'positive' 'positive' 'negative' 'negative' 'negative' 'positive'\n",
      " 'negative' 'positive' 'negative' 'positive' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'positive' 'positive' 'negative' 'positive' 'negative' 'negative'\n",
      " 'negative' 'positive' 'negative' 'negative' 'negative' 'positive'\n",
      " 'negative' 'negative' 'negative' 'positive' 'negative' 'negative'\n",
      " 'positive' 'negative' 'negative' 'negative' 'positive' 'negative'\n",
      " 'positive' 'positive' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'positive' 'negative' 'positive' 'negative'\n",
      " 'positive' 'negative' 'negative' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'positive' 'positive' 'negative' 'negative'\n",
      " 'positive' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'positive' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'positive' 'negative' 'negative' 'negative' 'positive'\n",
      " 'negative' 'negative' 'positive' 'positive' 'negative' 'negative'\n",
      " 'negative' 'positive' 'positive' 'negative' 'negative' 'positive'\n",
      " 'negative' 'positive' 'positive' 'negative' 'positive' 'negative'\n",
      " 'negative' 'positive' 'positive' 'positive' 'positive' 'negative'\n",
      " 'negative' 'positive' 'positive' 'negative' 'negative' 'negative'\n",
      " 'positive' 'positive' 'positive' 'negative' 'positive' 'negative'\n",
      " 'negative' 'positive' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'positive' 'negative' 'negative' 'negative' 'positive'\n",
      " 'negative' 'positive' 'positive' 'positive' 'positive' 'negative'\n",
      " 'positive' 'positive' 'negative' 'positive' 'negative' 'positive'\n",
      " 'negative' 'negative' 'negative' 'negative' 'positive' 'positive'\n",
      " 'positive' 'negative' 'positive' 'positive' 'negative' 'negative'\n",
      " 'negative' 'negative' 'positive' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'positive' 'positive' 'negative' 'negative'\n",
      " 'positive' 'positive' 'positive' 'negative' 'negative' 'negative'\n",
      " 'positive' 'negative' 'positive' 'negative' 'negative' 'negative'\n",
      " 'negative' 'positive' 'positive' 'negative' 'negative' 'negative'\n",
      " 'negative' 'positive' 'positive' 'positive' 'positive' 'negative'\n",
      " 'negative' 'negative' 'negative' 'positive' 'negative' 'negative'\n",
      " 'negative' 'negative' 'positive' 'negative' 'positive' 'positive'\n",
      " 'negative' 'negative' 'negative' 'positive' 'negative' 'negative'\n",
      " 'positive' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'positive' 'negative'\n",
      " 'positive' 'negative' 'positive' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'positive' 'negative' 'positive' 'positive'\n",
      " 'positive' 'positive' 'negative' 'positive' 'negative' 'negative'\n",
      " 'negative' 'negative' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'negative' 'positive' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'positive' 'negative' 'negative' 'positive' 'negative'\n",
      " 'positive' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'positive' 'negative' 'negative' 'negative'\n",
      " 'positive' 'negative' 'negative' 'negative' 'positive' 'negative'\n",
      " 'positive' 'negative' 'positive' 'positive' 'negative' 'positive'\n",
      " 'negative' 'negative' 'positive' 'positive' 'negative' 'negative'\n",
      " 'negative' 'positive' 'positive' 'negative' 'negative' 'negative'\n",
      " 'negative' 'positive' 'positive' 'negative' 'positive' 'negative'\n",
      " 'negative' 'positive' 'negative' 'negative' 'positive' 'positive'\n",
      " 'positive' 'positive' 'positive' 'positive' 'positive' 'negative'\n",
      " 'negative' 'positive' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'positive' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'positive' 'negative' 'negative' 'negative'\n",
      " 'positive' 'negative' 'negative' 'positive' 'positive' 'negative'\n",
      " 'negative' 'negative' 'positive' 'positive' 'negative' 'negative'\n",
      " 'positive' 'negative' 'positive' 'positive' 'negative' 'positive'\n",
      " 'negative' 'positive' 'positive' 'positive' 'negative' 'positive'\n",
      " 'negative' 'negative' 'positive' 'negative' 'negative' 'negative'\n",
      " 'negative' 'positive' 'positive' 'positive' 'positive' 'negative'\n",
      " 'negative' 'positive' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'positive' 'negative' 'negative' 'negative'\n",
      " 'positive' 'negative' 'negative' 'negative' 'positive' 'positive'\n",
      " 'negative' 'positive' 'negative' 'positive' 'negative' 'positive'\n",
      " 'positive' 'positive' 'negative' 'positive' 'negative' 'positive'\n",
      " 'positive' 'negative' 'negative' 'positive' 'negative' 'positive'\n",
      " 'positive' 'negative' 'positive' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'positive' 'positive' 'positive'\n",
      " 'negative' 'negative' 'negative' 'positive' 'negative' 'positive'\n",
      " 'negative' 'negative' 'negative' 'negative' 'positive' 'positive'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'positive'\n",
      " 'positive' 'positive' 'positive' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'negative' 'negative' 'negative' 'negative'\n",
      " 'positive' 'negative' 'negative' 'positive' 'negative' 'negative'\n",
      " 'negative' 'positive' 'negative' 'negative' 'negative' 'negative'\n",
      " 'positive' 'negative' 'positive' 'negative' 'positive' 'positive'\n",
      " 'positive' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'positive' 'negative' 'positive' 'positive' 'positive' 'positive'\n",
      " 'negative' 'positive' 'negative' 'negative' 'negative' 'negative'\n",
      " 'positive' 'positive' 'positive' 'positive' 'positive' 'negative'\n",
      " 'positive' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'positive'\n",
      " 'negative' 'negative' 'positive' 'negative' 'positive' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'positive' 'negative' 'negative' 'negative' 'positive' 'negative'\n",
      " 'negative' 'negative' 'positive' 'negative' 'positive' 'negative'\n",
      " 'positive' 'positive' 'negative' 'positive' 'negative' 'negative'\n",
      " 'positive' 'positive' 'negative' 'negative' 'negative' 'positive'\n",
      " 'positive' 'negative' 'negative' 'negative' 'negative' 'positive'\n",
      " 'positive' 'negative' 'positive' 'negative' 'negative' 'positive'\n",
      " 'negative' 'negative' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'positive' 'negative' 'negative' 'positive'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'positive' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'positive' 'negative' 'negative' 'negative' 'positive' 'negative'\n",
      " 'negative' 'positive' 'positive' 'negative' 'negative' 'negative'\n",
      " 'positive' 'positive' 'negative' 'negative' 'positive' 'negative'\n",
      " 'positive' 'positive' 'negative' 'positive' 'negative' 'negative'\n",
      " 'negative' 'positive' 'positive' 'positive' 'positive' 'positive'\n",
      " 'negative' 'positive' 'positive' 'negative' 'negative' 'positive'\n",
      " 'positive' 'positive' 'positive' 'negative' 'negative' 'positive'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'positive' 'negative' 'negative' 'negative' 'positive' 'negative'\n",
      " 'positive' 'positive' 'positive' 'positive' 'negative' 'negative'\n",
      " 'positive' 'positive' 'negative' 'negative' 'negative' 'negative'\n",
      " 'positive' 'negative' 'positive' 'positive' 'negative' 'negative'\n",
      " 'positive' 'negative' 'positive' 'positive' 'negative' 'positive'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'positive' 'positive' 'negative' 'negative'\n",
      " 'negative' 'negative' 'positive' 'positive' 'negative' 'positive'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'positive'\n",
      " 'positive' 'negative' 'negative' 'positive' 'positive' 'negative'\n",
      " 'negative' 'negative' 'negative' 'positive' 'negative' 'negative'\n",
      " 'negative' 'negative' 'positive' 'negative' 'positive' 'positive'\n",
      " 'negative' 'negative' 'negative' 'positive' 'negative' 'negative'\n",
      " 'positive' 'negative' 'negative' 'negative' 'positive' 'negative'\n",
      " 'positive' 'positive' 'negative' 'negative' 'negative' 'negative'\n",
      " 'positive' 'negative' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'negative' 'negative' 'negative' 'positive' 'positive'\n",
      " 'positive' 'negative' 'positive' 'negative' 'negative' 'positive'\n",
      " 'negative' 'negative' 'negative' 'positive' 'positive' 'negative'\n",
      " 'positive' 'negative' 'negative' 'positive' 'positive' 'positive'\n",
      " 'positive' 'negative' 'negative' 'negative' 'positive']\n"
     ]
    }
   ],
   "source": [
    "message1_vector = vector.transform(message1)\n",
    "print(classifier1.predict(message1_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['negative']\n"
     ]
    }
   ],
   "source": [
    "message2_vector = vector.transform(message2)\n",
    "print(classifier1.predict(message2_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('model.pkl', 'wb') as file:\n",
    "    pickle.dump(classifier1, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acuracy: 0.8772814359181204\n",
      "precision: 0.8772814359181204\n",
      "recall 0.8772814359181204\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.85      0.87      4930\n",
      "    positive       0.86      0.91      0.88      4987\n",
      "\n",
      "    accuracy                           0.88      9917\n",
      "   macro avg       0.88      0.88      0.88      9917\n",
      "weighted avg       0.88      0.88      0.88      9917\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "#create a classifier\n",
    "rbf1 = svm.SVC(kernel=\"rbf\", random_state = 4)\n",
    "#train the model\n",
    "rbf1.fit(xtrain,ytrain)\n",
    "#predict the response\n",
    "pred_rbf = rbf1.predict(xtest)\n",
    "\n",
    "#accuracy\n",
    "print(\"acuracy:\", metrics.accuracy_score(ytest,pred_rbf))\n",
    "#precision score\n",
    "print(\"precision:\", metrics.precision_score(ytest,pred_rbf, average='micro'))\n",
    "#recall score\n",
    "print(\"recall\" , metrics.recall_score(ytest,pred_rbf, average = 'micro'))\n",
    "print(metrics.classification_report(ytest,pred_rbf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[4183  747]\n",
      " [ 470 4517]]\n",
      "Accuracy: \n",
      " 0.8772814359181204\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(ytest, pred_rbf))\n",
    "print(\"Accuracy: \\n\", accuracy_score(ytest, pred_rbf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acuracy: 0.8709287082787133\n",
      "precision: 0.8709287082787133\n",
      "recall 0.8709287082787133\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.87      0.87      4930\n",
      "    positive       0.87      0.87      0.87      4987\n",
      "\n",
      "    accuracy                           0.87      9917\n",
      "   macro avg       0.87      0.87      0.87      9917\n",
      "weighted avg       0.87      0.87      0.87      9917\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "#creating a classifier\n",
    "cls = svm.SVC(kernel=\"linear\",C=1,random_state = 4)\n",
    "#training the model\n",
    "cls.fit(xtrain,ytrain)\n",
    "#predicting the response\n",
    "pred = cls.predict(xtest)\n",
    "\n",
    "\n",
    "# printing accuracy\n",
    "print(\"acuracy:\", metrics.accuracy_score(ytest,pred))\n",
    "#precision score\n",
    "print(\"precision:\", metrics.precision_score(ytest,pred, average = 'micro'))\n",
    "#recall score\n",
    "print(\"recall\" , metrics.recall_score(ytest,pred, average = 'micro'))\n",
    "print(metrics.classification_report(ytest, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', n_estimators=10, random_state=4)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier2 = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 4)\n",
    "classifier2.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['positive', 'positive', 'negative', ..., 'positive', 'negative',\n",
       "       'negative'], dtype='<U8')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predictions\n",
    "predictions = classifier1.predict(xtest)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34403    positive\n",
       "3542     positive\n",
       "43726    negative\n",
       "2060     positive\n",
       "40294    positive\n",
       "           ...   \n",
       "11721    negative\n",
       "28392    positive\n",
       "32777    positive\n",
       "23939    negative\n",
       "40642    negative\n",
       "Name: sentiment, Length: 9917, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.88      0.86      4930\n",
      "    positive       0.88      0.84      0.86      4987\n",
      "\n",
      "    accuracy                           0.86      9917\n",
      "   macro avg       0.86      0.86      0.86      9917\n",
      "weighted avg       0.86      0.86      0.86      9917\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(ytest,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4351  579]\n",
      " [ 812 4175]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.859735807199758"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "print(confusion_matrix(ytest, predictions))\n",
    "accuracy_score(ytest, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}